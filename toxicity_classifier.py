# -*- coding: utf-8 -*-
"""toxicity_classifier.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1US5s7EKNRmOOQkxhcWS9xENLdxCD0tD9
"""

import pandas as pd

train_df = pd.read_csv('sample_data/train.csv')

train_df.head()

train_df.isna().sum()

test_df = pd.read_csv('sample_data/test.csv')

test_df.head()

test_target = pd.read_csv('sample_data/test_labels.csv')

test_target.head()

len(train_df)

len(test_df)

len(test_target)

import re
import string

def  clean_text(text):
    text =  text.lower()
    text = re.sub(r"i'm", "i am", text)
    text = re.sub(r"\r", "", text)
    text = re.sub(r"he's", "he is", text)
    text = re.sub(r"she's", "she is", text)
    text = re.sub(r"it's", "it is", text)
    text = re.sub(r"that's", "that is", text)
    text = re.sub(r"what's", "that is", text)
    text = re.sub(r"where's", "where is", text)
    text = re.sub(r"how's", "how is", text)
    text = re.sub(r"\'ll", " will", text)
    text = re.sub(r"\'ve", " have", text)
    text = re.sub(r"\'re", " are", text)
    text = re.sub(r"\'d", " would", text)
    text = re.sub(r"\'re", " are", text)
    text = re.sub(r"won't", "will not", text)
    text = re.sub(r"can't", "cannot", text)
    text = re.sub(r"n't", " not", text)
    text = re.sub(r"n'", "ng", text)
    text = re.sub(r"'bout", "about", text)
    text = re.sub(r"'til", "until", text)
    text = re.sub(r"[-()\"#/@;:<>{}`+=~|.!?,]", "", text)
    text = text.translate(str.maketrans('', '', string.punctuation)) 
    text = re.sub("(\\W)"," ",text) 
    text = re.sub('\S*\d\S*\s*','', text)
    
    return text

train_df['comment_text'] = train_df['comment_text'].apply(lambda x:clean_text(x))

test_df['comment_text'] = test_df['comment_text'].apply(lambda x:clean_text(x))

train_df.head()

comments_df = train_df.drop(['id','comment_text'],axis = 1)
for i in comments_df.columns :
    print("Percent of {0}s in train data: ".format(i), round(100*comments_df[i].mean(),2), "%")

import nltk
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
from nltk.stem.snowball import SnowballStemmer

nltk.download('stopwords')
sn = SnowballStemmer(language='english')

def stemmer(text):
    words =  text.split()
    train = [sn.stem(word) for word in words if not word in set(stopwords.words('english'))]
    return ' '.join(train)

train_df.comment_text = train_df.comment_text.apply(stemmer)

train_df.comment_text.head()

X =  train_df.comment_text
y =  train_df.drop(['id','comment_text'],axis = 1)

from sklearn.model_selection import train_test_split

X_train,X_valid, y_train,y_valid= train_test_split(X,y,test_size=0.2, random_state=1)

X_train

y_train

from sklearn.feature_extraction.text import TfidfVectorizer

# Apply tfidfVectorizer
word_vectorizer = TfidfVectorizer(
    strip_accents='unicode',     
    analyzer='word',            
    token_pattern=r'\w{1,}',    
    ngram_range=(1, 3),         
    stop_words='english',
    sublinear_tf=True)

word_vectorizer.fit(X_train)    
train_word_features = word_vectorizer.transform(X_train)

X_train_transformed = word_vectorizer.transform(X_train)
X_valid_transformed = word_vectorizer.transform(X_valid)

from sklearn.linear_model import LogisticRegression
from sklearn import metrics
from sklearn.metrics import roc_auc_score , accuracy_score , confusion_matrix , f1_score
from sklearn.multiclass import OneVsRestClassifier

log_reg = LogisticRegression(C = 10, penalty='l2', solver = 'liblinear', random_state=45)

classifier = OneVsRestClassifier(log_reg)
classifier.fit(X_train_transformed, y_train)

y_train_pred_proba = classifier.predict_proba(X_train_transformed)
y_valid_pred_proba = classifier.predict_proba(X_valid_transformed)

roc_auc_score_train = roc_auc_score(y_train, y_train_pred_proba,average='weighted')
roc_auc_score_test = roc_auc_score(y_valid, y_valid_pred_proba,average='weighted')

print("ROC AUC Score Train:", roc_auc_score_train)
print("ROC AUC Score Test:", roc_auc_score_test)

import joblib

joblib.dump(word_vectorizer, open('vectroize2_jlib', 'wb'))
vectorizer = joblib.load('vectroize2_jlib')

def make_test_predictions(df,classifier):
    df.comment_text = df.comment_text.apply(clean_text)
    df.comment_text = df.comment_text.apply(stemmer)
    X_test = df.comment_text
    X_test =  X_test.to_numpy()
    X_test_transformed = vectorizer.transform(X_test)
    y_test_pred = classifier.predict_proba(X_test_transformed)
    result =  sum(y_test_pred[0])
    if result >=1 :
       return("Offensive Comment")
    else :
       return ("Normal Comment")

xx ={'id':[565],'comment_text':['Shut up your mouth bitch']}
xx = pd.DataFrame(xx)

make_test_predictions(xx,classifier)

xx ={'id':[565],'comment_text':['hi I am happy to be here']}
xx = pd.DataFrame(xx)

make_test_predictions(xx,classifier)

# Pickling the model
import pickle

pickle.dump(classifier, open('clf_model.pkl', 'wb'))

# Load the model
pickled_model=pickle.load(open('clf_model.pkl','rb'))

def make_predictions(df):
    df.comment_text = df.comment_text.apply(clean_text)
    df.comment_text = df.comment_text.apply(stemmer)
    X_test = df.comment_text
    X_test =  X_test.to_numpy()
    X_test_transformed = vectorizer.transform(X_test)
    pickled_model=pickle.load(open('clf_model.pkl','rb'))
    y_test_pred = pickled_model.predict_proba(X_test_transformed)
    result =  sum(y_test_pred[0])
    if result >=1 :
       return("Offensive Comment")
    else :
       return ("Normal Comment")

make_predictions(xx)

comment_text = "good to see you growing"
comment ={'id':[565],'comment_text':[comment_text]}
comment = pd.DataFrame(comment)
result = make_predictions(comment)
print(result)

